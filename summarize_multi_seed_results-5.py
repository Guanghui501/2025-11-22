#!/usr/bin/env python
"""
å¤šç§å­æ¶ˆèå®éªŒç»“æœæ±‡æ€»è„šæœ¬
ç”ŸæˆåŒ…å«å‡å€¼å’Œæ ‡å‡†å·®çš„è¯¦ç»†CSVæŠ¥å‘Š
"""

import json
import os
import sys
import argparse
from pathlib import Path
import numpy as np
import pandas as pd


def load_experiment_results(base_dir, exp_num, seed):
    """åŠ è½½å•ä¸ªå®éªŒçš„ç»“æœ"""
    exp_dir = Path(base_dir) / f"exp{exp_num}_seed{seed}"

    if not exp_dir.exists():
        return None

    history_val_file = exp_dir / "history_val.json"
    history_train_file = exp_dir / "history_train.json"

    if not history_val_file.exists():
        return None

    try:
        with open(history_val_file, 'r') as f:
            val_history = json.load(f)

        with open(history_train_file, 'r') as f:
            train_history = json.load(f)

        # æ£€æµ‹ä»»åŠ¡ç±»å‹
        if 'mae' in val_history:
            task_type = 'regression'
            metric_name = 'mae'
            val_metrics = val_history['mae']
            best_val = min(val_metrics)
            best_epoch = val_metrics.index(best_val)
        elif 'accuracy' in val_history:
            task_type = 'classification'
            metric_name = 'accuracy'
            val_metrics = val_history['accuracy']
            best_val = max(val_metrics)
            best_epoch = val_metrics.index(best_val)
        else:
            return None

        # æå–å…³é”®æŒ‡æ ‡
        result = {
            'task_type': task_type,
            'metric_name': metric_name,
            'total_epochs': len(val_history['epochs']),
            'best_epoch': val_history['epochs'][best_epoch],
            'best_val': best_val,
            'final_val': val_metrics[-1],
            'best_train_loss': train_history['loss'][best_epoch],
            'final_train_loss': train_history['loss'][-1],
        }

        # æ·»åŠ é¢å¤–æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if task_type == 'regression':
            if 'rmse' in val_history:
                result['best_val_rmse'] = min(val_history['rmse'])
                result['final_val_rmse'] = val_history['rmse'][-1]
        elif task_type == 'classification':
            if 'precision' in val_history:
                result['best_val_precision'] = max(val_history['precision'])
                result['final_val_precision'] = val_history['precision'][-1]
            if 'recall' in val_history:
                result['best_val_recall'] = max(val_history['recall'])
                result['final_val_recall'] = val_history['recall'][-1]
            if 'f1' in val_history:
                result['best_val_f1'] = max(val_history['f1'])
                result['final_val_f1'] = val_history['f1'][-1]

        return result

    except Exception as e:
        print(f"è­¦å‘Š: è¯»å– {exp_dir} æ—¶å‡ºé”™: {e}")
        return None


def load_full_model_results(model_dir):
    """åŠ è½½Full Modelçš„ç»“æœ"""
    model_dir = Path(model_dir)

    if not model_dir.exists():
        return None

    history_val_file = model_dir / "history_val.json"
    history_train_file = model_dir / "history_train.json"

    if not history_val_file.exists():
        return None

    try:
        with open(history_val_file, 'r') as f:
            val_history = json.load(f)

        with open(history_train_file, 'r') as f:
            train_history = json.load(f)

        # æ£€æµ‹ä»»åŠ¡ç±»å‹
        if 'mae' in val_history:
            task_type = 'regression'
            metric_name = 'mae'
            val_metrics = val_history['mae']
            best_val = min(val_metrics)
            best_epoch = val_metrics.index(best_val)
        elif 'accuracy' in val_history:
            task_type = 'classification'
            metric_name = 'accuracy'
            val_metrics = val_history['accuracy']
            best_val = max(val_metrics)
            best_epoch = val_metrics.index(best_val)
        else:
            return None

        # æå–å…³é”®æŒ‡æ ‡
        result = {
            'task_type': task_type,
            'metric_name': metric_name,
            'total_epochs': len(val_history['epochs']),
            'best_epoch': val_history['epochs'][best_epoch],
            'best_val': best_val,
            'final_val': val_metrics[-1],
            'best_train_loss': train_history['loss'][best_epoch],
            'final_train_loss': train_history['loss'][-1],
        }

        # æ·»åŠ é¢å¤–æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if task_type == 'regression':
            if 'rmse' in val_history:
                result['best_val_rmse'] = min(val_history['rmse'])
                result['final_val_rmse'] = val_history['rmse'][-1]
        elif task_type == 'classification':
            if 'precision' in val_history:
                result['best_val_precision'] = max(val_history['precision'])
                result['final_val_precision'] = val_history['precision'][-1]
            if 'recall' in val_history:
                result['best_val_recall'] = max(val_history['recall'])
                result['final_val_recall'] = val_history['recall'][-1]
            if 'f1' in val_history:
                result['best_val_f1'] = max(val_history['f1'])
                result['final_val_f1'] = val_history['f1'][-1]

        return result

    except Exception as e:
        print(f"è­¦å‘Š: è¯»å– {model_dir} æ—¶å‡ºé”™: {e}")
        return None


def summarize_results(base_dir, output_file=None, full_model_dir=None):
    """æ±‡æ€»æ‰€æœ‰å®éªŒç»“æœï¼ˆåŒ…æ‹¬Full Modelï¼‰"""

    base_dir = Path(base_dir)

    # è‡ªåŠ¨æ£€æµ‹Full Modelç›®å½•
    if full_model_dir is None:
        full_model_dir = base_dir.parent / "full_model_multi_seed"
    else:
        full_model_dir = Path(full_model_dir)

    # å®éªŒé…ç½®
    exp_configs = {
        1: {
            'name': 'Exp-1: Baseline',
            'short_name': 'Baseline',
            'description': 'Text Simple Concat (no cross-modal attention)',
            'use_cross_modal': False,
            'use_middle_fusion': False,
            'use_fine_grained': False,
        },
        2: {
            'name': 'Exp-2: +Late Fusion',
            'short_name': '+Late',
            'description': 'Late fusion with cross-modal attention',
            'use_cross_modal': True,
            'use_middle_fusion': False,
            'use_fine_grained': False,
        },
        3: {
            'name': 'Exp-3: +Middle Fusion',
            'short_name': '+Middle',
            'description': 'Late + Middle fusion (Innovation 1)',
            'use_cross_modal': True,
            'use_middle_fusion': True,
            'use_fine_grained': False,
        },
        4: {
            'name': 'Exp-4: +Fine-Grained',
            'short_name': '+FineGrained',
            'description': 'Late + Fine-grained attention (Innovation 2)',
            'use_cross_modal': True,
            'use_middle_fusion': False,
            'use_fine_grained': True,
        },
        5: {
            'name': 'Exp-5: Full Model',
            'short_name': 'Full',
            'description': 'All innovations combined',
            'use_cross_modal': True,
            'use_middle_fusion': True,
            'use_fine_grained': True,
        },
    }

    seeds = [42, 123, 7]

    # æ”¶é›†æ‰€æœ‰ç»“æœ
    all_results = []
    task_type = None
    metric_name = None

    print("="*80)
    print("ğŸ“Š å¤šç§å­æ¶ˆèå®éªŒç»“æœæ±‡æ€»ï¼ˆåŒ…æ‹¬Full Modelï¼‰")
    print("="*80)
    print(f"\næ¶ˆèå®éªŒç›®å½•: {base_dir}")
    print(f"Full Modelç›®å½•: {full_model_dir}\n")

    for exp_num in range(1, 6):
        config = exp_configs[exp_num]

        print(f"\n{config['name']}")
        print("-" * 60)

        exp_results = []

        for seed in seeds:
            # Exp-5 (Full Model) å¯ä»¥ä»æ¶ˆèç›®å½•æˆ–ç‹¬ç«‹ç›®å½•åŠ è½½
            if exp_num == 5:
                # é¦–å…ˆå°è¯•ä»æ¶ˆèå®éªŒç›®å½•åŠ è½½ï¼ˆexp5_seedæ ¼å¼ï¼‰
                result = load_experiment_results(base_dir, exp_num, seed)

                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»Full Modelç‹¬ç«‹ç›®å½•åŠ è½½ï¼ˆfull_model_seedæ ¼å¼ï¼‰
                if result is None:
                    model_dir = full_model_dir / f"full_model_seed{seed}"
                    if model_dir.exists():
                        result = load_full_model_results(model_dir)
            else:
                # Exp-1åˆ°Exp-4ä»æ¶ˆèå®éªŒç›®å½•åŠ è½½
                result = load_experiment_results(base_dir, exp_num, seed)

            if result is not None:
                if task_type is None:
                    task_type = result['task_type']
                    metric_name = result['metric_name']

                exp_results.append(result)

                # æ‰“å°å•ä¸ªç§å­çš„ç»“æœ
                print(f"  Seed {seed:3d}: "
                      f"{metric_name}={result['best_val']:.4f} "
                      f"(epoch {result['best_epoch']}, "
                      f"total {result['total_epochs']} epochs)")
            else:
                print(f"  Seed {seed:3d}: æœªå®Œæˆæˆ–æ•°æ®ç¼ºå¤±")

        if exp_results:
            # è®¡ç®—ç»Ÿè®¡é‡
            best_vals = [r['best_val'] for r in exp_results]
            mean_val = np.mean(best_vals)
            std_val = np.std(best_vals, ddof=1) if len(best_vals) > 1 else 0

            print(f"\n  ç»Ÿè®¡: {metric_name} = {mean_val:.4f} Â± {std_val:.4f}")
            print(f"  å®Œæˆæ•°: {len(exp_results)}/{len(seeds)}")

            # æ·»åŠ åˆ°æ€»ç»“æœ
            summary = {
                'exp_num': exp_num,
                'exp_name': config['name'],
                'short_name': config['short_name'],
                'description': config['description'],
                'use_cross_modal': config['use_cross_modal'],
                'use_middle_fusion': config['use_middle_fusion'],
                'use_fine_grained': config['use_fine_grained'],
                'num_completed': len(exp_results),
                'mean_best_val': mean_val,
                'std_best_val': std_val,
                'individual_results': exp_results,
            }

            all_results.append(summary)

    # ========================================================================
    # ç”ŸæˆCSVæŠ¥å‘Š
    # ========================================================================
    print("\n" + "="*80)
    print("ğŸ“„ ç”ŸæˆCSVæŠ¥å‘Š")
    print("="*80)

    if not all_results:
        print("\nâŒ æ²¡æœ‰å¯ç”¨çš„ç»“æœæ•°æ®ï¼")
        return

    # CSV 1: ç®€æ˜æ±‡æ€»ï¼ˆå‡å€¼Â±æ ‡å‡†å·®ï¼‰
    csv_rows = []
    for summary in all_results:
        row = {
            'Experiment': summary['short_name'],
            'Description': summary['description'],
            'Cross-Modal': 'âœ“' if summary['use_cross_modal'] else 'âœ—',
            'Middle Fusion': 'âœ“' if summary['use_middle_fusion'] else 'âœ—',
            'Fine-Grained': 'âœ“' if summary['use_fine_grained'] else 'âœ—',
            'Completed': f"{summary['num_completed']}/3",
            f'Best {metric_name.upper()} (MeanÂ±Std)':
                f"{summary['mean_best_val']:.4f}Â±{summary['std_best_val']:.4f}",
        }
        csv_rows.append(row)

    df_summary = pd.DataFrame(csv_rows)

    summary_csv = base_dir / "ablation_summary.csv"
    df_summary.to_csv(summary_csv, index=False)
    print(f"\nâœ… ç®€æ˜æ±‡æ€»å·²ä¿å­˜: {summary_csv}")

    # CSV 2: è¯¦ç»†ç»“æœï¼ˆåŒ…å«æ¯ä¸ªç§å­ï¼‰
    detailed_rows = []
    for summary in all_results:
        for i, seed in enumerate(seeds):
            if i < len(summary['individual_results']):
                result = summary['individual_results'][i]
                row = {
                    'Experiment': summary['short_name'],
                    'Seed': seed,
                    'Total Epochs': result['total_epochs'],
                    'Best Epoch': result['best_epoch'],
                    f'Best Val {metric_name.upper()}': result['best_val'],
                    f'Final Val {metric_name.upper()}': result['final_val'],
                    'Best Train Loss': result['best_train_loss'],
                    'Final Train Loss': result['final_train_loss'],
                }

                # æ·»åŠ é¢å¤–æŒ‡æ ‡
                if task_type == 'regression' and 'best_val_rmse' in result:
                    row['Best Val RMSE'] = result['best_val_rmse']
                    row['Final Val RMSE'] = result['final_val_rmse']
                elif task_type == 'classification':
                    if 'best_val_precision' in result:
                        row['Best Val Precision'] = result['best_val_precision']
                    if 'best_val_recall' in result:
                        row['Best Val Recall'] = result['best_val_recall']
                    if 'best_val_f1' in result:
                        row['Best Val F1'] = result['best_val_f1']

                detailed_rows.append(row)

    df_detailed = pd.DataFrame(detailed_rows)

    detailed_csv = base_dir / "ablation_detailed.csv"
    df_detailed.to_csv(detailed_csv, index=False)
    print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜: {detailed_csv}")

    # ========================================================================
    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    # ========================================================================
    print("\n" + "="*80)
    print("ğŸ“Š æ€§èƒ½å¯¹æ¯”è¡¨")
    print("="*80)
    print()

    print(df_summary.to_string(index=False))

    # ========================================================================
    # åˆ†ææ”¹è¿›æ•ˆæœ
    # ========================================================================
    print("\n" + "="*80)
    print("ğŸ“ˆ æ”¹è¿›æ•ˆæœåˆ†æ")
    print("="*80)
    print()

    if len(all_results) >= 2:
        baseline = all_results[0]

        print(f"åŸºçº¿ (Baseline): {baseline['mean_best_val']:.4f} Â± {baseline['std_best_val']:.4f}")
        print()

        for summary in all_results[1:]:
            improvement = baseline['mean_best_val'] - summary['mean_best_val']
            improvement_pct = (improvement / baseline['mean_best_val']) * 100

            if task_type == 'regression':
                direction = "é™ä½" if improvement > 0 else "å¢åŠ "
            else:
                direction = "æå‡" if improvement > 0 else "ä¸‹é™"

            print(f"{summary['short_name']:20s}: "
                  f"{summary['mean_best_val']:.4f} Â± {summary['std_best_val']:.4f} "
                  f"â†’ {direction} {abs(improvement):.4f} ({abs(improvement_pct):.2f}%)")

        print()

        # æœ€ä½³æ¨¡å‹
        if task_type == 'regression':
            best_exp = min(all_results, key=lambda x: x['mean_best_val'])
        else:
            best_exp = max(all_results, key=lambda x: x['mean_best_val'])

        print(f"ğŸ† æœ€ä½³é…ç½®: {best_exp['short_name']} "
              f"({metric_name.upper()} = {best_exp['mean_best_val']:.4f} Â± {best_exp['std_best_val']:.4f})")

    print("\n" + "="*80)
    print("âœ… æ±‡æ€»å®Œæˆï¼")
    print("="*80)
    print()


def main():
    parser = argparse.ArgumentParser(description='å¤šç§å­æ¶ˆèå®éªŒç»“æœæ±‡æ€»ï¼ˆåŒ…æ‹¬Full Modelï¼‰')
    parser.add_argument('--ablation_dir', type=str, default='./ablation_multi_seed',
                        help='æ¶ˆèå®éªŒåŸºç¡€ç›®å½•')
    parser.add_argument('--full_model_dir', type=str, default=None,
                        help='Full Modelè®­ç»ƒç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹ä¸º ../full_model_multi_seedï¼‰')
    parser.add_argument('--output', type=str, default=None,
                        help='è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')

    args = parser.parse_args()

    if not os.path.exists(args.ablation_dir):
        print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {args.ablation_dir}")
        sys.exit(1)

    summarize_results(args.ablation_dir, args.output, args.full_model_dir)


if __name__ == '__main__':
    main()
